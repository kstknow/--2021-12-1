{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비지도 학습 감성분석 - Lexicon 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordnet Synset 및 Sentiwordnet SentiSynset 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus   import wordnet  \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\asdfg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus   import wordnet    # wordnet에 있는 sentiword을 사용\n",
    "\n",
    "term = 'present'\n",
    "synsets = wordnet.synsets(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 18)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(synsets), len(synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('present.n.01'), Synset('present.n.02'), Synset('present.n.03'), Synset('show.v.01'), Synset('present.v.02'), Synset('stage.v.01'), Synset('present.v.04'), Synset('present.v.05'), Synset('award.v.01'), Synset('give.v.08'), Synset('deliver.v.01'), Synset('introduce.v.01'), Synset('portray.v.04'), Synset('confront.v.03'), Synset('present.v.12'), Synset('salute.v.06'), Synset('present.a.01'), Synset('present.a.02')]\n"
     ]
    }
   ],
   "source": [
    "print(synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### name: present.n.01 ####\n",
      "POS: noun.time\n",
      "정의: <bound method Synset.definition of Synset('present.n.01')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('present.n.01')>\n",
      "#### name: present.n.02 ####\n",
      "POS: noun.possession\n",
      "정의: <bound method Synset.definition of Synset('present.n.02')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('present.n.02')>\n",
      "#### name: present.n.03 ####\n",
      "POS: noun.communication\n",
      "정의: <bound method Synset.definition of Synset('present.n.03')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('present.n.03')>\n",
      "#### name: show.v.01 ####\n",
      "POS: verb.perception\n",
      "정의: <bound method Synset.definition of Synset('show.v.01')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('show.v.01')>\n",
      "#### name: present.v.02 ####\n",
      "POS: verb.communication\n",
      "정의: <bound method Synset.definition of Synset('present.v.02')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('present.v.02')>\n",
      "#### name: stage.v.01 ####\n",
      "POS: verb.creation\n",
      "정의: <bound method Synset.definition of Synset('stage.v.01')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('stage.v.01')>\n",
      "#### name: present.v.04 ####\n",
      "POS: verb.possession\n",
      "정의: <bound method Synset.definition of Synset('present.v.04')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('present.v.04')>\n",
      "#### name: present.v.05 ####\n",
      "POS: verb.stative\n",
      "정의: <bound method Synset.definition of Synset('present.v.05')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('present.v.05')>\n",
      "#### name: award.v.01 ####\n",
      "POS: verb.possession\n",
      "정의: <bound method Synset.definition of Synset('award.v.01')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('award.v.01')>\n",
      "#### name: give.v.08 ####\n",
      "POS: verb.possession\n",
      "정의: <bound method Synset.definition of Synset('give.v.08')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('give.v.08')>\n",
      "#### name: deliver.v.01 ####\n",
      "POS: verb.communication\n",
      "정의: <bound method Synset.definition of Synset('deliver.v.01')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('deliver.v.01')>\n",
      "#### name: introduce.v.01 ####\n",
      "POS: verb.communication\n",
      "정의: <bound method Synset.definition of Synset('introduce.v.01')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('introduce.v.01')>\n",
      "#### name: portray.v.04 ####\n",
      "POS: verb.creation\n",
      "정의: <bound method Synset.definition of Synset('portray.v.04')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('portray.v.04')>\n",
      "#### name: confront.v.03 ####\n",
      "POS: verb.communication\n",
      "정의: <bound method Synset.definition of Synset('confront.v.03')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('confront.v.03')>\n",
      "#### name: present.v.12 ####\n",
      "POS: verb.communication\n",
      "정의: <bound method Synset.definition of Synset('present.v.12')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('present.v.12')>\n",
      "#### name: salute.v.06 ####\n",
      "POS: verb.communication\n",
      "정의: <bound method Synset.definition of Synset('salute.v.06')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('salute.v.06')>\n",
      "#### name: present.a.01 ####\n",
      "POS: adj.all\n",
      "정의: <bound method Synset.definition of Synset('present.a.01')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('present.a.01')>\n",
      "#### name: present.a.02 ####\n",
      "POS: adj.all\n",
      "정의: <bound method Synset.definition of Synset('present.a.02')>\n",
      "표제어: <bound method Synset.lemma_names of Synset('present.a.02')>\n"
     ]
    }
   ],
   "source": [
    "for synset in synsets:\n",
    "    print(f'#### name: {synset.name()} ####')\n",
    "    print('POS:', synset.lexname())\n",
    "    print('정의:', synset.definition)\n",
    "    print('표제어:', synset.lemma_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 어휘간의 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiger.n.01 a fierce or audacious person\n",
      "tiger.n.02 large feline of forests in most of Asia having a tawny coat with black stripes; endangered\n"
     ]
    }
   ],
   "source": [
    "for synset in wordnet.synsets('tiger'):\n",
    "    print(synset.name(), synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어, 품사를 아는 경우에는 synset()\n",
    "tiger = wordnet.synset('tiger.n.02')\n",
    "tree = wordnet.synset('tree.n.01')\n",
    "lion = wordnet.synset('lion.n.01')\n",
    "cat = wordnet.synset('cat.n.01')\n",
    "dog =wordnet.synset('dog.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3333333333333333, 0.25, 0.07142857142857142)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어간의 유사도\n",
    "tiger.path_similarity(lion),tiger.path_similarity(cat), tiger.path_similarity(tree),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개 단어간의 유사도\n",
    "similarities = []\n",
    "entities =[tree, lion, tiger, cat, dog]\n",
    "\n",
    "for entity in entities:\n",
    "    similarity = [entity.path_similarity(another) for another in entities]\n",
    "    similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(similarities, columns= ['tree','lion', 'tiger','cat', 'dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tree      lion     tiger       cat       dog\n",
       "0  1.000000  0.071429  0.071429  0.076923  0.125000\n",
       "1  0.071429  1.000000  0.333333  0.250000  0.166667\n",
       "2  0.071429  0.333333  1.000000  0.250000  0.166667\n",
       "3  0.076923  0.250000  0.250000  1.000000  0.200000\n",
       "4  0.125000  0.166667  0.166667  0.200000  1.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SentiSynset 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\asdfg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\sentiwordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet\n",
    "\n",
    "senti_synsets = list(sentiwordnet.senti_synsets('slow'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "9\n",
      "[SentiSynset('father.n.01'), SentiSynset('forefather.n.01'), SentiSynset('father.n.03'), SentiSynset('church_father.n.01'), SentiSynset('father.n.05'), SentiSynset('father.n.06'), SentiSynset('founder.n.02'), SentiSynset('don.n.03'), SentiSynset('beget.v.01')]\n"
     ]
    }
   ],
   "source": [
    "print(type(senti_synsets))\n",
    "print(len(senti_synsets))\n",
    "print(senti_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "9\n",
      "[SentiSynset('father.n.01'), SentiSynset('forefather.n.01'), SentiSynset('father.n.03'), SentiSynset('church_father.n.01'), SentiSynset('father.n.05'), SentiSynset('father.n.06'), SentiSynset('founder.n.02'), SentiSynset('don.n.03'), SentiSynset('beget.v.01')]\n"
     ]
    }
   ],
   "source": [
    "senti_synsets = list(sentiwordnet.senti_synsets('father'))\n",
    "print(type(senti_synsets))\n",
    "print(len(senti_synsets))\n",
    "print(senti_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FATHER 단어의 긍정감성 지수, 부정감정 지수, 객관성 지수\n",
    "father = sentiwordnet.senti_synset('father.n.01')\n",
    "father.pos_score(), father.neg_score(), father.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mother 단어의 긍정감성 지수, 부정감정 지수, 객관성 지수\n",
    "mother = sentiwordnet.senti_synset('mother.n.01')\n",
    "mother.pos_score(), mother.neg_score(), mother.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.875, 0.125, 0.0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fabulous 단어의 긍정감성 지수, 부정감정 지수, 객관성 지수\n",
    "fabulous = sentiwordnet.senti_synset('fabulous.a.01')\n",
    "fabulous.pos_score(), fabulous.neg_score(), fabulous.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.0, 0.5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# work 단어의 긍정감성 지수, 부정감정 지수, 객관성 지수\n",
    "work = sentiwordnet.senti_synset('love.v.01')\n",
    "work.pos_score(), work.neg_score(), work.obj_score() \n",
    "# 동사에는 감성지수 값이 없다.\n",
    "# 긍정 감성 지수가 잇는 것은 명사, 형용사, 부사 3가지만 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('just.a.01'),\n",
       " SentiSynset('equitable.a.01'),\n",
       " SentiSynset('fair.a.01'),\n",
       " SentiSynset('good.s.07'),\n",
       " SentiSynset('merely.r.01'),\n",
       " SentiSynset('precisely.r.01'),\n",
       " SentiSynset('just.r.03'),\n",
       " SentiSynset('just.r.04'),\n",
       " SentiSynset('barely.r.01'),\n",
       " SentiSynset('just.r.06')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sentiwordnet.senti_synsets('just'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('n', 'a', 'r', 'v')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.NOUN, wordnet.ADJ, wordnet.ADV, wordnet.VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 감성지수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', \"'s\", 'good', 'to', 'see', 'you', 'again', '.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "sentence = \"It's good to see you again.\"\n",
    "word_list =word_tokenize(sentence)\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\asdfg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('good', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('again', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = ('good', 'JJ')\n",
    "tag[1].startswith(\"J\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It PRP\n",
      "'s VBZ\n",
      "good JJ\n",
      "to TO\n",
      "see VB\n",
      "you PRP\n",
      "again RB\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for word, tag in pos_tag(word_list):\n",
    "    print(word, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It None\n",
      "'s v\n",
      "good a\n",
      "to None\n",
      "see v\n",
      "you None\n",
      "again r\n",
      ". None\n"
     ]
    }
   ],
   "source": [
    "for word, tag in pos_tag(word_list):\n",
    "    print(word, penn_to_wn(tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'see', 'you', 'again']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentemce로부터 senti_synset 객체를 만드는 과정\n",
    "sentence = \"It's good to see you again.\"\n",
    "word_list = [word for word in word_tokenize(sentence) if len(word) > 2]\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<good.a.01: PosScore=0.75 NegScore=0.0>\n",
      "<see.n.01: PosScore=0.0 NegScore=0.0>\n",
      "<again.r.01: PosScore=0.0 NegScore=0.0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for word, tag in pos_tag(word_list):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag:\n",
    "        synsets = list(sentiwordnet.senti_synsets(word, wn_tag))\n",
    "        synset = synsets[0]\n",
    "        print(synset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = 0.0\n",
    "for word, tag in pos_tag(word_list):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag:\n",
    "        synsets = list(sentiwordnet.senti_synsets(word, wn_tag))\n",
    "        synset = synsets[0]\n",
    "        sentiment += synset.pos_score() - synset.neg_score()\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer() # 객체를 하나 만든다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = 0.0\n",
    "for word, tag in pos_tag(word_list):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag:\n",
    "        lemma = lemmatizer.lemmatize(word, wn_tag)\n",
    "        synsets = list(sentiwordnet.senti_synsets(lemma, wn_tag))\n",
    "        synset = synsets[0]\n",
    "        sentiment += synset.pos_score() - synset.neg_score()\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(sentiwordnet.senti_synsets('present')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(sentiwordnet.senti_synsets('present', 'n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "document = \"I watched this video at a friend's house. I'm glad I did not waste money buying this one. The video cover has a scene from the 1975 movie Capricorn One. The movie starts out with several clips of rocket blow-ups, most not related to manned flight. Sibrel's smoking gun is a short video clip of the astronauts preparing a video broadcast. He edits in his own voice-over instead of letting us listen to what the crew had to say. The video curiously ends with a showing of the Zapruder film. His claims about radiation, shielding, star photography, and others lead me to believe is he extremely ignorant or has some sort of ax to grind against NASA, the astronauts, or American in general. His science is bad, and so is this video.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene\n",
      "blow-ups\n",
      "Sibrel\n",
      "voice-over\n",
      "Zapruder\n",
      "others\n",
      "부정\n"
     ]
    }
   ],
   "source": [
    "sentiment = 0.0\n",
    "for sentence in sent_tokenize(document):\n",
    "    word_list = [word for word in word_tokenize(sentence) if len(word) > 2]\n",
    "    for word, tag in pos_tag(word_list):\n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        if wn_tag:\n",
    "            lemma = lemmatizer.lemmatize(word, wn_tag)\n",
    "            synsets = list(sentiwordnet.senti_synsets(lemma, wn_tag))\n",
    "            if not synsets:\n",
    "                print(word)\n",
    "                continue\n",
    "            synset = synsets[0]\n",
    "            sentiment += synset.pos_score() - synset.neg_score()    \n",
    "print('긍정' if sentiment >= 0 else '부정')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<filter at 0x19aab5fcdf0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiwordnet.senti_synsets('they')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 감성을 계산해주는 함수는 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swn_polarity(text):\n",
    "    # 감성 지수 초기화 \n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산 \n",
    "    for raw_sentence in raw_sentences:\n",
    "        # NTLK 기반의 품사 태깅 문장 추출  \n",
    "        word_list = [word for word in word_tokenize(raw_sentence) if len(word) > 2]\n",
    "        tagged_sentence = pos_tag(word_list)\n",
    "        for word, tag in tagged_sentence:\n",
    "            # WordNet 기반 품사 태깅과 어근 추출\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wordnet.NOUN, wordnet.ADJ, wordnet.ADV, wordnet.VERB):\n",
    "                continue                   \n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    "            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성. \n",
    "            synsets = wordnet.synsets(lemma, pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    "            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
    "            # 모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산. \n",
    "            synset = synsets[0]\n",
    "            swn_synset = sentiwordnet.senti_synset(synset.name())\n",
    "            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())           \n",
    "            tokens_count += 1\n",
    "    \n",
    "    if not tokens_count:\n",
    "        return 0\n",
    "    \n",
    "    # 총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\n",
    "    return 1 if sentiment >= 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IMDB 영화 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/labeledTrainData.tsv', sep ='\\t',quoting =3)    #3 :QUOTE-None\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <br /> 태그는 공백으로 변환\n",
    "df.review = df.review.str.replace('<br />', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영문자 이외는 공백으로 변환 구둣점, 숫자제거 - 영문자가 아닌 글자는 공백으로 변환\n",
    "df.review = df.review.str.replace('[^A-Za-z]', ' ').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.iloc[:1000, :]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 9s\n"
     ]
    }
   ],
   "source": [
    "%time df['pred'] = df.review.apply(lambda x: swn_polarity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62568"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(df.sentiment, df.pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER Lexicon 을 이용한 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\asdfg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.13, 'neu': 0.743, 'pos': 0.127, 'compound': -0.7943}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "senti_analyzer = SentimentIntensityAnalyzer()\n",
    "senti_score = senti_analyzer.polarity_scores(df.review[0])\n",
    "senti_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_polarity(document, threshold):\n",
    "    score = senti_analyzer.polarity_scores(document)\n",
    "    return 1 if score['compound'] >= threshold else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%time df['vader pred'] = df.review.apply(lambda x: vader_polarity(x, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.685"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df.sentiment, df['vader pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>pred</th>\n",
       "      <th>vader pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  pred  vader pred\n",
       "0          1     1           0\n",
       "1          1     1           1\n",
       "2          0     0           0\n",
       "3          0     0           1\n",
       "4          1     0           1"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf = df[['sentiment', 'pred', 'vader pred']]\n",
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ced85cc735450c97a1603f741adec25d487c05b2555d996cef925db138a315ba"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
